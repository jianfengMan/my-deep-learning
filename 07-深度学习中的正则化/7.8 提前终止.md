​	在每次验证集误差有所改善后，我们存储模型参数的副本。当训练算法终止时，我们返回这些参数而不是最新 的参数。当验证集上的误差在事先指定的循环次数内没有进一步改善时，算法就会 终止。这种策略被称为**提前终止(early stopping)**

​	提前终止是一种非常不显眼的正则化形式，它几乎不需要改变基本训练过程、 目标函数或一组允许的参数值。这意味着，无需破坏学习动态就能很容易地使用提 前终止。相对于权重衰减，必须小心不能使用太多的权重衰减，以防网络陷入不良局 部极小点(对应于病态的小权重)。

提前终止需要验证集，这意味着某些训练数据不能被馈送到模型

提前终止具有正则化效果