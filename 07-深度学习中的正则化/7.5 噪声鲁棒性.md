对于某些模型而言， 向输入添加方差极小的噪声等价于对权重施加范数惩罚 

正则化模型的噪声使用方式是将其加到权重、主要用于循环神经网络 



标签平滑(label smoothing)通过把确切分类目标从 0 和
1 替换成 ε /(k-1)和 1 − ε，正则化具有 k 个输出的 softmax 函数 的模型

标准交叉熵 损失可以用在这些非确切目标的输出上

 softmax 函数 和明确目标的最大似然 学习可能永远不会收敛——softmax 函数 永远无法真正预测 0 概率或 1 概率

使用如权重衰减等其他正则化策略 能够防止这种情况。标签平滑的优势是能够防止模型追求确切概率而不影响模型学 习正确分类。