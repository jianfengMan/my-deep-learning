Dropout提供了一种廉价的Bagging集成近似，能够训练和评估指数 级数量的神经网络

Dropout训练的集成包括所有从基础网络除去非输出单元后形成的子 网络

​	Dropout训练与Bagging训练不太一样。在Bagging的情况下，所有模型都是独立的。在Dropout的情况下，所有模型共享参数，其中每个模型继承父神经网络参数 的不同子集。参数共享使得在有限可用的内存下表示指数级数量的模型变得可能

​	在Dropout的情况 下，通常大部分模型都没有显式地被训练，因为通常父神经网络会很大，以致于到 宇宙毁灭都不可能采样完所有的子网络。取而代之的是，在单个步骤中我们训练一 小部分的子网络，参数共享会使得剩余的子网络也能有好的参数设定

​	但是两者每个子网络中遇到的训练集都是又放回采样的原始训练集的一个子集。