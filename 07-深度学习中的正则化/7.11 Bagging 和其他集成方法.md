Bagging(bootstrap aggregating)是通过结合几个模型降低泛化误差的技术

​	主要想法是分别训练几个不同的模型，然后让所有模型表决测试样例的输出。这是机器学习中常规策略的一个例子，被称为模型平均(model averaging)。采用这种策略的技术被称为集成方法

​	模型平均(model averaging)奏效的原因是不同的模型通常不会在测试集上产 生完全相同的误差

​	集成的每个成员可以使用 不同的算法和目标函数训练成完全不同的模型。Bagging是一种允许重复多次使用同 一种模型、训练算法和目标函数的方法。

​	模型平均是一个减少泛化误差的非常强大可靠的方法