如果项目是以固定大小的向量作 为输入的监督学习，那么可以使用全连接的前馈网络。如果输入有已知的拓扑结构 (例如，输入是图像)，那么可以使用卷积网络。在这些情况下，刚开始可以使用某 些分段线性单元(ReLU或者其扩展，如Leaky ReLU、PReLU和maxout)。如果输
入或输出是一个序列，可以使用门控循环网络(LSTM 或 GRU）

具有衰减学习率以及动量的 SGD 是优化算法一个合理的选择(流行的衰减方 法有，衰减到固定最低学习率的线性衰减、指数衰减，或每次发生验证错误停滞时 将学习率降低 2 − 10 倍，这些衰减方法在不同问题上好坏不一

另一个非常合理 的选择是 Adam 算法。批标准化对优化性能有着显著的影响，特别是对卷积网络和 具有 sigmoid 非线性函数的网络而言。虽然在最初的基准中忽略批标准化是合理的， 然而当优化似乎出现问题时，应该立刻使用批标准化。

