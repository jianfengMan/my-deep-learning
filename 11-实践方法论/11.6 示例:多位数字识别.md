许多现代神经网络的实现基于图形处理器(Graphics Processing Unit, GPU)。 图形处理器(GPU)最初是为图形应用而开发的专用硬件组件

由于神经网络能够被分为多个单独的 ‘‘神经元’’，并 且独立于同一层内其他神经元进行处理，所以神经网络可以从 GPU 的并行特性中 受益匪浅。



GPU 另一个常见的设定是使一个组中的所有线 程都同时执行同一指令。这意味着 GPU 难以执行分支操作。线程被分为一个个称作 warp 的小组。在一个 warp 中的每一个线程在每一个循环中执行同一指令，所以 当同一个 warp 中的不同线程需要执行不同的指令时，需要使用串行而非并行的方 式。

因为每一个输入的样本都可以在单独的机器上运
行。这也被称为数据并行(data parallelism),模型并行(model parallelism)也是可行的，其中多个机器共同运行一
个数据点，每一个机器负责模型的一个部分。对于推断和训练，这都是可行的



异步随机梯度下降:对于随机梯度下降的单步 来说，我们可以增加小批量的大小，但是从优化性能的角度来说，我们得到的回报通 常并不会线性增长。使用多个机器并行地计算多个梯度下降步骤是一个更好的选择。 不幸的是，梯度下降的标准定义完全是一个串行的过程:第 t 步的梯度是第 t − 1 步 所得参数的函数。在这个方法中，几个处理 器的核共用存有参数的内存。每一个核在无锁情况下读取这些参数并计算对应的梯 度，然后在无锁状态下更新这些参数。由于一些核把其他的核所更新的参数覆盖了， 因此这种方法减少了每一步梯度下降所获得的平均提升。但因为更新步数的速率增加，总体上还是加快了学习过程



减少推断所需开销的一个关键策略是模型压缩(model compression) 模型压缩的基本思想是用一个更小的模型取代原始耗时的模型，从而 使得用来存储与评估所需的内存与运行时间更少.

在分类器中加速推断的可行策略是使用 级联(cascade)的分类器。当目标是检 测罕见对象(或事件)是否存在时，可以应用级联策略